{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0078c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob   \n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import spacy\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt \n",
    "#import tensorflow as tf\n",
    "#import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4e7692",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9428f737",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = pd.read_csv(\"nikol.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23273d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn.dropna()\n",
    "dfn['Tweets'] = dfn['Tweets'].str.replace('https', '')\n",
    "\n",
    "dfn['polarity'] = dfn['Tweets'].apply(lambda x: TextBlob(x).polarity)\n",
    "\n",
    "label = []\n",
    "for pol in dfn['polarity']:\n",
    "    if 0 < pol <= 1.0 :    label.append('positive')\n",
    "    elif -1.0 <= pol < 0:   label.append('negative')\n",
    "    elif pol == 0:  label.append('neutral')\n",
    "        \n",
    "        \n",
    "dfn['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fff202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe = pd.read_csv('marukyan.csv')\n",
    "dfe.dropna()\n",
    "dfe['Tweets'] = dfe['Tweets'].str.replace('https', '')\n",
    "\n",
    "dfe['polarity'] = dfe['Tweets'].apply(lambda x: TextBlob(x).polarity)\n",
    "\n",
    "label = []\n",
    "for pol in dfe['polarity']:\n",
    "    if 0 < pol <= 1.0 :    label.append('positive')\n",
    "    elif -1.0 <= pol < 0:   label.append('negative')\n",
    "    elif pol == 0:  label.append('neutral')\n",
    "        \n",
    "        \n",
    "dfe['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "027b4ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = pd.read_csv('mirzoyan.csv')\n",
    "dfa.dropna()\n",
    "dfa['Tweets'] = dfa['Tweets'].str.replace('https', '')\n",
    "\n",
    "dfa['polarity'] = dfa['Tweets'].apply(lambda x: TextBlob(x).polarity)\n",
    "\n",
    "label = []\n",
    "for pol in dfa['polarity']:\n",
    "    if 0 < pol <= 1.0 :    label.append('positive')\n",
    "    elif -1.0 <= pol < 0:   label.append('negative')\n",
    "    elif pol == 0:  label.append('neutral')\n",
    "        \n",
    "        \n",
    "dfa['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8031c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "all = pd.concat([dfn, dfe,dfa])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "196f096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(all, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5f8fda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'positive', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4c2553f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Created</th>\n",
       "      <th>Number of Likes</th>\n",
       "      <th>Source of Tweet</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>polarity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>236</td>\n",
       "      <td>131</td>\n",
       "      <td>4</td>\n",
       "      <td>239</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>1131</td>\n",
       "      <td>264</td>\n",
       "      <td>4</td>\n",
       "      <td>1209</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>692</td>\n",
       "      <td>291</td>\n",
       "      <td>4</td>\n",
       "      <td>711</td>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date Created  Number of Likes  Source of Tweet  Tweets  polarity  \\\n",
       "label                                                                        \n",
       "negative           236              131                4     239       113   \n",
       "neutral           1131              264                4    1209         1   \n",
       "positive           692              291                4     711       312   \n",
       "\n",
       "          label  \n",
       "label            \n",
       "negative      1  \n",
       "neutral       1  \n",
       "positive      1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('label').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e351cb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>Դա հնավոր էր անել համավարակի առկայության պայմա...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Had a meeting with @morton_wendy today, where ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Why AZ is punishing 120K people of NK, includi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>We welcome the statement of @ExtSpoxEU! Detent...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>On July 29, starting from 11:00 pm, the air de...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Tweets     label\n",
       "1291  Դա հնավոր էր անել համավարակի առկայության պայմա...   neutral\n",
       "135   Had a meeting with @morton_wendy today, where ...   neutral\n",
       "88    Why AZ is punishing 120K people of NK, includi...  positive\n",
       "626   We welcome the statement of @ExtSpoxEU! Detent...  positive\n",
       "447   On July 29, starting from 11:00 pm, the air de...   neutral"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train[['Tweets','label']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d40bbd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Tweets\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa430eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depure_data(data):\n",
    "    \n",
    "    #Removing URLs with a regular expression\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    data = url_pattern.sub(r'', data)\n",
    "\n",
    "    # Remove Emails\n",
    "    data = re.sub('\\S*@\\S*\\s?', '', data)\n",
    "\n",
    "    # Remove new line characters\n",
    "    data = re.sub('\\s+', ' ', data)\n",
    "\n",
    "    # Remove distracting single quotes\n",
    "    data = re.sub(\"\\'\", \"\", data)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c13a71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Դա հնավոր էր անել համավարակի առկայության պայմաններում և նույնիսկ պարտադիր էր, քանի որ մենք ամեն օր չենք նշում Անկախության հռչակագրի 30-ամյակը։ Ինչևիցե... շնորհավորում եմ բոլորիս, ինչպես հայաստանցիներին, այնպես էլ աշխարհասփյուռ հայությանը այս բացառիկ տոնի առթիվ։',\n",
       " 'Had a meeting with today, where I mentioned that none of the global powers can stay indifferent to the issue of the immediate return of #Armenian prisoners of war from #Azerbaijan. ://t.co/Htd6IBeWlY',\n",
       " 'Why AZ is punishing 120K people of NK, including 30K children? I insist that AZ is doing this to NK for its democratic choice, which sustains for 30 years already. Today NK has no gas and totally blocked. NK Armenians are waiting for the reaction &amp; real steps from int. community. ://t.co/QBFjOtUXI3',\n",
       " 'We welcome the statement of Detention of Armenian POWs by Azerbaijan is a war crime! We demand the immediate release of Armenian prisoners of war and civilians held captive in Azerbaijan, as well as special attention of the international community to this issue.',\n",
       " 'On July 29, starting from 11:00 pm, the air defence units of the RA Armed Forces suspended attempts of UAVs to enter the airspace of the Republic of #Armenia on the #Gegharkunik region of the #Armenian-#Azerbaijani border. ']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = []\n",
    "#Splitting pd.Series to list\n",
    "data_to_list = train['Tweets'].values.tolist()\n",
    "for i in range(len(data_to_list)):\n",
    "    temp.append(depure_data(data_to_list[i]))\n",
    "list(temp[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85b94712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['դա', 'հնավոր', 'էր', 'անել', 'համավարակի', 'առկայության', 'պայմաններում', 'նույնիսկ', 'պարտադիր', 'էր', 'քանի', 'որ', 'մենք', 'ամեն', 'օր', 'չենք', 'նշում', 'անկախության', 'հռչակագրի', 'ամյակը', 'ինչևիցե', 'շնորհավորում', 'եմ', 'բոլորիս', 'ինչպես', 'հայաստանցիներին', 'այնպես', 'էլ', 'աշխարհասփյուռ', 'հայությանը', 'այս', 'բացառիկ', 'տոնի', 'առթիվ'], ['had', 'meeting', 'with', 'today', 'where', 'mentioned', 'that', 'none', 'of', 'the', 'global', 'powers', 'can', 'stay', 'indifferent', 'to', 'the', 'issue', 'of', 'the', 'immediate', 'return', 'of', 'armenian', 'prisoners', 'of', 'war', 'from', 'azerbaijan', 'co', 'htd', 'ibewly'], ['why', 'az', 'is', 'punishing', 'people', 'of', 'nk', 'including', 'children', 'insist', 'that', 'az', 'is', 'doing', 'this', 'to', 'nk', 'for', 'its', 'democratic', 'choice', 'which', 'sustains', 'for', 'years', 'already', 'today', 'nk', 'has', 'no', 'gas', 'and', 'totally', 'blocked', 'nk', 'armenians', 'are', 'waiting', 'for', 'the', 'reaction', 'amp', 'real', 'steps', 'from', 'int', 'community', 'co', 'qbfjotuxi'], ['we', 'welcome', 'the', 'statement', 'of', 'detention', 'of', 'armenian', 'pows', 'by', 'azerbaijan', 'is', 'war', 'crime', 'we', 'demand', 'the', 'immediate', 'release', 'of', 'armenian', 'prisoners', 'of', 'war', 'and', 'civilians', 'held', 'captive', 'in', 'azerbaijan', 'as', 'well', 'as', 'special', 'attention', 'of', 'the', 'international', 'community', 'to', 'this', 'issue'], ['on', 'july', 'starting', 'from', 'pm', 'the', 'air', 'defence', 'units', 'of', 'the', 'ra', 'armed', 'forces', 'suspended', 'attempts', 'of', 'uavs', 'to', 'enter', 'the', 'airspace', 'of', 'the', 'republic', 'of', 'armenia', 'on', 'the', 'gegharkunik', 'region', 'of', 'the', 'armenian', 'azerbaijani', 'border'], ['we', 'request', 'your', 'immediate', 'intervention', 'to', 'ensure', 'the', 'protection', 'of', 'the', 'rights', 'of', 'armenian', 'prisoners', 'of', 'war', 'to', 'prevent', 'the', 'perpetration', 'of', 'another', 'war', 'crime', 'by', 'the', 'azerbaijani', 'authorities', 'co', 'ahxzt', 'xbo'], ['good', 'news', 'from', 'armenia', 'the', 'first', 'patient', 'diagnosed', 'with', 'covid', 'has', 'recovered'], ['my', 'last', 'interview', 'to', 'news', 'co', 'jofnfb'], ['welcomed', 'my', 'colleague', 'sg', 'of', 'in', 'yerevan', 'we', 'had', 'productive', 'discussions', 'on', 'our', 'armenia', 'coe', 'coop', 'for', 'strengthening', 'democratic', 'institutions', 'human', 'rights', 'amp', 'rule', 'of', 'law', 'in', 'armenia', 'reiterated', 'that', 'path', 'of', 'democratic', 'development', 'is', 'irreversible', 'in', 'our', 'country', 'co', 'znx', 'uoeahu'], ['in', 'particular', 'having', 'regard', 'to', 'the', 'diverse', 'assistance', 'of', 'turkey', 'to', 'the', 'azerbaijani', 'attacks', 'against', 'the', 'civilian', 'population', 'amp', 'objects', 'of', 'arstakh', 'and', 'armenia', 'in', 'the', 'gross', 'violation', 'of', 'international', 'humanitarian', 'law', 'amp', 'the', 'european', 'convention', 'on', 'human', 'rights']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "        \n",
    "\n",
    "data_words = list(sent_to_words(temp))\n",
    "\n",
    "print(data_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46607003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2164"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1616de3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detokenize(text):\n",
    "    return TreebankWordDetokenizer().detokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "310b6c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['դա հնավոր էր անել համավարակի առկայության պայմաններում նույնիսկ պարտադիր էր քանի որ մենք ամեն օր չենք նշում անկախության հռչակագրի ամյակը ինչևիցե շնորհավորում եմ բոլորիս ինչպես հայաստանցիներին այնպես էլ աշխարհասփյուռ հայությանը այս բացառիկ տոնի առթիվ', 'had meeting with today where mentioned that none of the global powers can stay indifferent to the issue of the immediate return of armenian prisoners of war from azerbaijan co htd ibewly', 'why az is punishing people of nk including children insist that az is doing this to nk for its democratic choice which sustains for years already today nk has no gas and totally blocked nk armenians are waiting for the reaction amp real steps from int community co qbfjotuxi', 'we welcome the statement of detention of armenian pows by azerbaijan is war crime we demand the immediate release of armenian prisoners of war and civilians held captive in azerbaijan as well as special attention of the international community to this issue', 'on july starting from pm the air defence units of the ra armed forces suspended attempts of uavs to enter the airspace of the republic of armenia on the gegharkunik region of the armenian azerbaijani border']\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(len(data_words)):\n",
    "    data.append(detokenize(data_words[i]))\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be5ef948",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9bce09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(train['label'])\n",
    "y = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 'neutral':\n",
    "        y.append(0)\n",
    "    if labels[i] == 'negative':\n",
    "        y.append(1)\n",
    "    if labels[i] == 'positive':\n",
    "        y.append(2)\n",
    "y = np.array(y)\n",
    "labels = tf.keras.utils.to_categorical(y, 3, dtype=\"float32\")\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99d32177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2164"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b9eb46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "786c7f9e",
   "metadata": {},
   "source": [
    "## Data sequencing and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8672b277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ... 1537 2795 1538]\n",
      " [   0    0    0 ...    4 4545 4546]\n",
      " [   0    0    0 ...   54    4 4550]\n",
      " ...\n",
      " [   0    0    0 ...   76  466    4]\n",
      " [   0    0    0 ...  357  517  794]\n",
      " [   0    0    0 ...  456    4 4524]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "max_words = 5000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data)\n",
    "sequences = tokenizer.texts_to_sequences(data)\n",
    "tweets = pad_sequences(sequences, maxlen=max_len)\n",
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3faee74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a80f0834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1623 541 1623 541\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tweets,labels, random_state=0)\n",
    "print (len(X_train),len(X_test),len(y_train),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa529230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8db564c8",
   "metadata": {},
   "source": [
    "## Single LSTM layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad0ebb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.9202 - accuracy: 0.5662\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55638, saving model to best_model1.hdf5\n",
      "51/51 [==============================] - 17s 206ms/step - loss: 0.9202 - accuracy: 0.5662 - val_loss: 0.8379 - val_accuracy: 0.5564\n",
      "Epoch 2/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.7486 - accuracy: 0.6913\n",
      "Epoch 2: val_accuracy improved from 0.55638 to 0.73383, saving model to best_model1.hdf5\n",
      "51/51 [==============================] - 8s 154ms/step - loss: 0.7486 - accuracy: 0.6913 - val_loss: 0.7401 - val_accuracy: 0.7338\n",
      "Epoch 3/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.6993 - accuracy: 0.7147\n",
      "Epoch 3: val_accuracy did not improve from 0.73383\n",
      "51/51 [==============================] - 8s 158ms/step - loss: 0.6993 - accuracy: 0.7147 - val_loss: 0.7448 - val_accuracy: 0.6969\n",
      "Epoch 4/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.6584 - accuracy: 0.7277\n",
      "Epoch 4: val_accuracy improved from 0.73383 to 0.74492, saving model to best_model1.hdf5\n",
      "51/51 [==============================] - 8s 166ms/step - loss: 0.6584 - accuracy: 0.7277 - val_loss: 0.6757 - val_accuracy: 0.7449\n",
      "Epoch 5/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.6182 - accuracy: 0.7535\n",
      "Epoch 5: val_accuracy improved from 0.74492 to 0.75231, saving model to best_model1.hdf5\n",
      "51/51 [==============================] - 10s 186ms/step - loss: 0.6182 - accuracy: 0.7535 - val_loss: 0.6547 - val_accuracy: 0.7523\n",
      "Epoch 6/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.5626 - accuracy: 0.7733\n",
      "Epoch 6: val_accuracy did not improve from 0.75231\n",
      "51/51 [==============================] - 9s 181ms/step - loss: 0.5626 - accuracy: 0.7733 - val_loss: 0.6353 - val_accuracy: 0.7523\n",
      "Epoch 7/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.5197 - accuracy: 0.7917\n",
      "Epoch 7: val_accuracy did not improve from 0.75231\n",
      "51/51 [==============================] - 8s 164ms/step - loss: 0.5197 - accuracy: 0.7917 - val_loss: 0.6486 - val_accuracy: 0.7486\n",
      "Epoch 8/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.4704 - accuracy: 0.8201\n",
      "Epoch 8: val_accuracy improved from 0.75231 to 0.75786, saving model to best_model1.hdf5\n",
      "51/51 [==============================] - 9s 171ms/step - loss: 0.4704 - accuracy: 0.8201 - val_loss: 0.6473 - val_accuracy: 0.7579\n",
      "Epoch 9/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.4373 - accuracy: 0.8330\n",
      "Epoch 9: val_accuracy improved from 0.75786 to 0.76340, saving model to best_model1.hdf5\n",
      "51/51 [==============================] - 8s 155ms/step - loss: 0.4373 - accuracy: 0.8330 - val_loss: 0.6327 - val_accuracy: 0.7634\n",
      "Epoch 10/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.4042 - accuracy: 0.8404\n",
      "Epoch 10: val_accuracy did not improve from 0.76340\n",
      "51/51 [==============================] - 9s 179ms/step - loss: 0.4042 - accuracy: 0.8404 - val_loss: 0.6550 - val_accuracy: 0.7486\n",
      "Epoch 11/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3679 - accuracy: 0.8497\n",
      "Epoch 11: val_accuracy improved from 0.76340 to 0.78004, saving model to best_model1.hdf5\n",
      "51/51 [==============================] - 9s 185ms/step - loss: 0.3679 - accuracy: 0.8497 - val_loss: 0.6031 - val_accuracy: 0.7800\n",
      "Epoch 12/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3641 - accuracy: 0.8534\n",
      "Epoch 12: val_accuracy did not improve from 0.78004\n",
      "51/51 [==============================] - 9s 173ms/step - loss: 0.3641 - accuracy: 0.8534 - val_loss: 0.6102 - val_accuracy: 0.7782\n",
      "Epoch 13/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3211 - accuracy: 0.8638\n",
      "Epoch 13: val_accuracy did not improve from 0.78004\n",
      "51/51 [==============================] - 9s 176ms/step - loss: 0.3211 - accuracy: 0.8638 - val_loss: 0.6313 - val_accuracy: 0.7800\n",
      "Epoch 14/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2898 - accuracy: 0.8694\n",
      "Epoch 14: val_accuracy did not improve from 0.78004\n",
      "51/51 [==============================] - 9s 180ms/step - loss: 0.2898 - accuracy: 0.8694 - val_loss: 0.6143 - val_accuracy: 0.7800\n",
      "Epoch 15/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2672 - accuracy: 0.8780\n",
      "Epoch 15: val_accuracy improved from 0.78004 to 0.79298, saving model to best_model1.hdf5\n",
      "51/51 [==============================] - 9s 171ms/step - loss: 0.2672 - accuracy: 0.8780 - val_loss: 0.6152 - val_accuracy: 0.7930\n",
      "Epoch 16/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2414 - accuracy: 0.8860\n",
      "Epoch 16: val_accuracy did not improve from 0.79298\n",
      "51/51 [==============================] - 9s 179ms/step - loss: 0.2414 - accuracy: 0.8860 - val_loss: 0.6170 - val_accuracy: 0.7708\n",
      "Epoch 17/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2202 - accuracy: 0.9051\n",
      "Epoch 17: val_accuracy did not improve from 0.79298\n",
      "51/51 [==============================] - 9s 169ms/step - loss: 0.2202 - accuracy: 0.9051 - val_loss: 0.6550 - val_accuracy: 0.7893\n",
      "Epoch 18/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2000 - accuracy: 0.9125\n",
      "Epoch 18: val_accuracy did not improve from 0.79298\n",
      "51/51 [==============================] - 9s 172ms/step - loss: 0.2000 - accuracy: 0.9125 - val_loss: 0.6587 - val_accuracy: 0.7616\n",
      "Epoch 19/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1892 - accuracy: 0.9254\n",
      "Epoch 19: val_accuracy did not improve from 0.79298\n",
      "51/51 [==============================] - 8s 153ms/step - loss: 0.1892 - accuracy: 0.9254 - val_loss: 0.6477 - val_accuracy: 0.7800\n",
      "Epoch 20/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.9489\n",
      "Epoch 20: val_accuracy did not improve from 0.79298\n",
      "51/51 [==============================] - 9s 187ms/step - loss: 0.1616 - accuracy: 0.9489 - val_loss: 0.7476 - val_accuracy: 0.7800\n",
      "Epoch 21/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1563 - accuracy: 0.9556\n",
      "Epoch 21: val_accuracy did not improve from 0.79298\n",
      "51/51 [==============================] - 10s 192ms/step - loss: 0.1563 - accuracy: 0.9556 - val_loss: 0.6996 - val_accuracy: 0.7856\n",
      "Epoch 22/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1312 - accuracy: 0.9587\n",
      "Epoch 22: val_accuracy did not improve from 0.79298\n",
      "51/51 [==============================] - 10s 188ms/step - loss: 0.1312 - accuracy: 0.9587 - val_loss: 0.7373 - val_accuracy: 0.7782\n",
      "Epoch 23/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1226 - accuracy: 0.9606\n",
      "Epoch 23: val_accuracy did not improve from 0.79298\n",
      "51/51 [==============================] - 9s 180ms/step - loss: 0.1226 - accuracy: 0.9606 - val_loss: 0.6879 - val_accuracy: 0.7745\n",
      "Epoch 24/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1166 - accuracy: 0.9680\n",
      "Epoch 24: val_accuracy did not improve from 0.79298\n",
      "51/51 [==============================] - 10s 194ms/step - loss: 0.1166 - accuracy: 0.9680 - val_loss: 0.7064 - val_accuracy: 0.7911\n",
      "Epoch 25/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1007 - accuracy: 0.9661\n",
      "Epoch 25: val_accuracy did not improve from 0.79298\n",
      "51/51 [==============================] - 10s 187ms/step - loss: 0.1007 - accuracy: 0.9661 - val_loss: 0.7571 - val_accuracy: 0.7911\n",
      "Epoch 26/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0888 - accuracy: 0.9772\n",
      "Epoch 26: val_accuracy did not improve from 0.79298\n",
      "51/51 [==============================] - 10s 190ms/step - loss: 0.0888 - accuracy: 0.9772 - val_loss: 0.7836 - val_accuracy: 0.7856\n",
      "Epoch 27/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0849 - accuracy: 0.9735\n",
      "Epoch 27: val_accuracy did not improve from 0.79298\n",
      "51/51 [==============================] - 9s 170ms/step - loss: 0.0849 - accuracy: 0.9735 - val_loss: 0.7567 - val_accuracy: 0.7819\n",
      "Epoch 28/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.9791\n",
      "Epoch 28: val_accuracy did not improve from 0.79298\n",
      "51/51 [==============================] - 9s 182ms/step - loss: 0.0726 - accuracy: 0.9791 - val_loss: 0.7818 - val_accuracy: 0.7837\n",
      "Epoch 29/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.9877\n",
      "Epoch 29: val_accuracy improved from 0.79298 to 0.79482, saving model to best_model1.hdf5\n",
      "51/51 [==============================] - 10s 194ms/step - loss: 0.0602 - accuracy: 0.9877 - val_loss: 0.7704 - val_accuracy: 0.7948\n",
      "Epoch 30/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9877\n",
      "Epoch 30: val_accuracy did not improve from 0.79482\n",
      "51/51 [==============================] - 9s 170ms/step - loss: 0.0488 - accuracy: 0.9877 - val_loss: 0.7958 - val_accuracy: 0.7763\n",
      "Epoch 31/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9871\n",
      "Epoch 31: val_accuracy did not improve from 0.79482\n",
      "51/51 [==============================] - 9s 181ms/step - loss: 0.0432 - accuracy: 0.9871 - val_loss: 0.8167 - val_accuracy: 0.7837\n",
      "Epoch 32/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9864\n",
      "Epoch 32: val_accuracy did not improve from 0.79482\n",
      "51/51 [==============================] - 9s 176ms/step - loss: 0.0488 - accuracy: 0.9864 - val_loss: 0.8067 - val_accuracy: 0.7726\n",
      "Epoch 33/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9895\n",
      "Epoch 33: val_accuracy did not improve from 0.79482\n",
      "51/51 [==============================] - 9s 183ms/step - loss: 0.0365 - accuracy: 0.9895 - val_loss: 0.8663 - val_accuracy: 0.7856\n",
      "Epoch 34/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9908\n",
      "Epoch 34: val_accuracy improved from 0.79482 to 0.80037, saving model to best_model1.hdf5\n",
      "51/51 [==============================] - 9s 183ms/step - loss: 0.0326 - accuracy: 0.9908 - val_loss: 0.9022 - val_accuracy: 0.8004\n",
      "Epoch 35/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1684 - accuracy: 0.9600\n",
      "Epoch 35: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 8s 162ms/step - loss: 0.1684 - accuracy: 0.9600 - val_loss: 0.8592 - val_accuracy: 0.7985\n",
      "Epoch 36/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9908\n",
      "Epoch 36: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 174ms/step - loss: 0.0330 - accuracy: 0.9908 - val_loss: 0.8850 - val_accuracy: 0.7856\n",
      "Epoch 37/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9945\n",
      "Epoch 37: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 181ms/step - loss: 0.0208 - accuracy: 0.9945 - val_loss: 0.8888 - val_accuracy: 0.7819\n",
      "Epoch 38/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9908\n",
      "Epoch 38: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 180ms/step - loss: 0.0291 - accuracy: 0.9908 - val_loss: 0.9479 - val_accuracy: 0.7930\n",
      "Epoch 39/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9926\n",
      "Epoch 39: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 184ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 0.9753 - val_accuracy: 0.7893\n",
      "Epoch 40/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9920\n",
      "Epoch 40: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 177ms/step - loss: 0.0223 - accuracy: 0.9920 - val_loss: 0.9677 - val_accuracy: 0.7745\n",
      "Epoch 41/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9963\n",
      "Epoch 41: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 184ms/step - loss: 0.0183 - accuracy: 0.9963 - val_loss: 0.9927 - val_accuracy: 0.7911\n",
      "Epoch 42/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9914\n",
      "Epoch 42: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 181ms/step - loss: 0.0219 - accuracy: 0.9914 - val_loss: 1.0146 - val_accuracy: 0.7893\n",
      "Epoch 43/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9945\n",
      "Epoch 43: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 176ms/step - loss: 0.0226 - accuracy: 0.9945 - val_loss: 0.9904 - val_accuracy: 0.7856\n",
      "Epoch 44/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9975\n",
      "Epoch 44: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 184ms/step - loss: 0.0110 - accuracy: 0.9975 - val_loss: 1.0674 - val_accuracy: 0.7911\n",
      "Epoch 45/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9951\n",
      "Epoch 45: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 181ms/step - loss: 0.0197 - accuracy: 0.9951 - val_loss: 1.0450 - val_accuracy: 0.7930\n",
      "Epoch 46/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9975\n",
      "Epoch 46: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 185ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 1.0264 - val_accuracy: 0.7874\n",
      "Epoch 47/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9975\n",
      "Epoch 47: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 177ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 1.1262 - val_accuracy: 0.7893\n",
      "Epoch 48/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9969\n",
      "Epoch 48: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 10s 188ms/step - loss: 0.0184 - accuracy: 0.9969 - val_loss: 1.0643 - val_accuracy: 0.7948\n",
      "Epoch 49/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9969\n",
      "Epoch 49: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 179ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 1.0498 - val_accuracy: 0.7930\n",
      "Epoch 50/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9994\n",
      "Epoch 50: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 178ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 1.1531 - val_accuracy: 0.7837\n",
      "Epoch 51/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9982\n",
      "Epoch 51: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 177ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 1.0898 - val_accuracy: 0.7893\n",
      "Epoch 52/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9975\n",
      "Epoch 52: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 10s 188ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 1.2263 - val_accuracy: 0.7856\n",
      "Epoch 53/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9988\n",
      "Epoch 53: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 169ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 1.1130 - val_accuracy: 0.7856\n",
      "Epoch 54/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9982\n",
      "Epoch 54: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 185ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 1.1726 - val_accuracy: 0.7967\n",
      "Epoch 55/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9969\n",
      "Epoch 55: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 10s 190ms/step - loss: 0.0074 - accuracy: 0.9969 - val_loss: 1.1369 - val_accuracy: 0.7911\n",
      "Epoch 56/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9963\n",
      "Epoch 56: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 185ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 1.2711 - val_accuracy: 0.7911\n",
      "Epoch 57/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 57: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 172ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 1.2165 - val_accuracy: 0.7911\n",
      "Epoch 58/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9988\n",
      "Epoch 58: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 178ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 1.2430 - val_accuracy: 0.7911\n",
      "Epoch 59/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9969\n",
      "Epoch 59: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 176ms/step - loss: 0.0075 - accuracy: 0.9969 - val_loss: 1.2262 - val_accuracy: 0.7874\n",
      "Epoch 60/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 60: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 172ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3199 - val_accuracy: 0.7967\n",
      "Epoch 61/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9975\n",
      "Epoch 61: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 176ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 1.2345 - val_accuracy: 0.7911\n",
      "Epoch 62/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9969\n",
      "Epoch 62: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 182ms/step - loss: 0.0073 - accuracy: 0.9969 - val_loss: 1.2039 - val_accuracy: 0.7874\n",
      "Epoch 63/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9994\n",
      "Epoch 63: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 180ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 1.1979 - val_accuracy: 0.7893\n",
      "Epoch 64/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9982\n",
      "Epoch 64: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 9s 178ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 1.2931 - val_accuracy: 0.7930\n",
      "Epoch 65/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9988\n",
      "Epoch 65: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 8s 165ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 1.2796 - val_accuracy: 0.7930\n",
      "Epoch 66/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9982\n",
      "Epoch 66: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 8s 149ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 1.3443 - val_accuracy: 0.7911\n",
      "Epoch 67/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9982\n",
      "Epoch 67: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 8s 149ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 1.2906 - val_accuracy: 0.7948\n",
      "Epoch 68/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9994\n",
      "Epoch 68: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 7s 145ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 1.2552 - val_accuracy: 0.7911\n",
      "Epoch 69/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9988\n",
      "Epoch 69: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 8s 147ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 1.3233 - val_accuracy: 0.7911\n",
      "Epoch 70/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9951\n",
      "Epoch 70: val_accuracy did not improve from 0.80037\n",
      "51/51 [==============================] - 8s 151ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 1.2194 - val_accuracy: 0.7800\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(layers.Embedding(max_words, 20))\n",
    "model1.add(layers.LSTM(15,dropout=0.5))\n",
    "model1.add(layers.Dense(3,activation='softmax'))\n",
    "\n",
    "\n",
    "model1.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#Implementing model checkpoins to save the best metric and do not lose it on training.\n",
    "checkpoint1 = ModelCheckpoint(\"best_model1.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
    "history = model1.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e6a981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c5a8810",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f613fb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.8949 - accuracy: 0.5853\n",
      "Epoch 1: val_accuracy improved from -inf to 0.70980, saving model to best_model2.hdf5\n",
      "51/51 [==============================] - 19s 219ms/step - loss: 0.8949 - accuracy: 0.5853 - val_loss: 0.8070 - val_accuracy: 0.7098\n",
      "Epoch 2/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.7287 - accuracy: 0.7073\n",
      "Epoch 2: val_accuracy improved from 0.70980 to 0.72828, saving model to best_model2.hdf5\n",
      "51/51 [==============================] - 8s 147ms/step - loss: 0.7287 - accuracy: 0.7073 - val_loss: 0.7128 - val_accuracy: 0.7283\n",
      "Epoch 3/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.6891 - accuracy: 0.7172\n",
      "Epoch 3: val_accuracy improved from 0.72828 to 0.73937, saving model to best_model2.hdf5\n",
      "51/51 [==============================] - 8s 151ms/step - loss: 0.6891 - accuracy: 0.7172 - val_loss: 0.6819 - val_accuracy: 0.7394\n",
      "Epoch 4/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.6503 - accuracy: 0.7295\n",
      "Epoch 4: val_accuracy did not improve from 0.73937\n",
      "51/51 [==============================] - 8s 153ms/step - loss: 0.6503 - accuracy: 0.7295 - val_loss: 0.6793 - val_accuracy: 0.7301\n",
      "Epoch 5/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.5929 - accuracy: 0.7603\n",
      "Epoch 5: val_accuracy did not improve from 0.73937\n",
      "51/51 [==============================] - 9s 169ms/step - loss: 0.5929 - accuracy: 0.7603 - val_loss: 0.7608 - val_accuracy: 0.6950\n",
      "Epoch 6/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.5452 - accuracy: 0.7850\n",
      "Epoch 6: val_accuracy improved from 0.73937 to 0.75601, saving model to best_model2.hdf5\n",
      "51/51 [==============================] - 8s 166ms/step - loss: 0.5452 - accuracy: 0.7850 - val_loss: 0.6224 - val_accuracy: 0.7560\n",
      "Epoch 7/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.4962 - accuracy: 0.8084\n",
      "Epoch 7: val_accuracy improved from 0.75601 to 0.76710, saving model to best_model2.hdf5\n",
      "51/51 [==============================] - 8s 159ms/step - loss: 0.4962 - accuracy: 0.8084 - val_loss: 0.6188 - val_accuracy: 0.7671\n",
      "Epoch 8/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.4460 - accuracy: 0.8324\n",
      "Epoch 8: val_accuracy improved from 0.76710 to 0.77264, saving model to best_model2.hdf5\n",
      "51/51 [==============================] - 9s 169ms/step - loss: 0.4460 - accuracy: 0.8324 - val_loss: 0.6156 - val_accuracy: 0.7726\n",
      "Epoch 9/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.4185 - accuracy: 0.8392\n",
      "Epoch 9: val_accuracy did not improve from 0.77264\n",
      "51/51 [==============================] - 9s 173ms/step - loss: 0.4185 - accuracy: 0.8392 - val_loss: 0.6126 - val_accuracy: 0.7726\n",
      "Epoch 10/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3836 - accuracy: 0.8478\n",
      "Epoch 10: val_accuracy did not improve from 0.77264\n",
      "51/51 [==============================] - 8s 150ms/step - loss: 0.3836 - accuracy: 0.8478 - val_loss: 0.5912 - val_accuracy: 0.7726\n",
      "Epoch 11/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3538 - accuracy: 0.8558\n",
      "Epoch 11: val_accuracy improved from 0.77264 to 0.78373, saving model to best_model2.hdf5\n",
      "51/51 [==============================] - 8s 150ms/step - loss: 0.3538 - accuracy: 0.8558 - val_loss: 0.5798 - val_accuracy: 0.7837\n",
      "Epoch 12/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3245 - accuracy: 0.8608\n",
      "Epoch 12: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 149ms/step - loss: 0.3245 - accuracy: 0.8608 - val_loss: 0.5981 - val_accuracy: 0.7726\n",
      "Epoch 13/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2956 - accuracy: 0.8768\n",
      "Epoch 13: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 150ms/step - loss: 0.2956 - accuracy: 0.8768 - val_loss: 0.6247 - val_accuracy: 0.7782\n",
      "Epoch 14/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2728 - accuracy: 0.8885\n",
      "Epoch 14: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 148ms/step - loss: 0.2728 - accuracy: 0.8885 - val_loss: 0.6404 - val_accuracy: 0.7763\n",
      "Epoch 15/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2504 - accuracy: 0.9014\n",
      "Epoch 15: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 148ms/step - loss: 0.2504 - accuracy: 0.9014 - val_loss: 0.6436 - val_accuracy: 0.7726\n",
      "Epoch 16/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.9137\n",
      "Epoch 16: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 148ms/step - loss: 0.2261 - accuracy: 0.9137 - val_loss: 0.6882 - val_accuracy: 0.7800\n",
      "Epoch 17/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2075 - accuracy: 0.9242\n",
      "Epoch 17: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 148ms/step - loss: 0.2075 - accuracy: 0.9242 - val_loss: 0.6631 - val_accuracy: 0.7745\n",
      "Epoch 18/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1892 - accuracy: 0.9372\n",
      "Epoch 18: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 151ms/step - loss: 0.1892 - accuracy: 0.9372 - val_loss: 0.7180 - val_accuracy: 0.7763\n",
      "Epoch 19/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 0.9316\n",
      "Epoch 19: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 148ms/step - loss: 0.1798 - accuracy: 0.9316 - val_loss: 0.7192 - val_accuracy: 0.7726\n",
      "Epoch 20/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1563 - accuracy: 0.9452\n",
      "Epoch 20: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 149ms/step - loss: 0.1563 - accuracy: 0.9452 - val_loss: 0.8419 - val_accuracy: 0.7689\n",
      "Epoch 21/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1517 - accuracy: 0.9464\n",
      "Epoch 21: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 149ms/step - loss: 0.1517 - accuracy: 0.9464 - val_loss: 0.7397 - val_accuracy: 0.7505\n",
      "Epoch 22/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1478 - accuracy: 0.9519\n",
      "Epoch 22: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 148ms/step - loss: 0.1478 - accuracy: 0.9519 - val_loss: 0.7939 - val_accuracy: 0.7763\n",
      "Epoch 23/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1223 - accuracy: 0.9587\n",
      "Epoch 23: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 149ms/step - loss: 0.1223 - accuracy: 0.9587 - val_loss: 0.8480 - val_accuracy: 0.7782\n",
      "Epoch 24/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 0.9569\n",
      "Epoch 24: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 148ms/step - loss: 0.1152 - accuracy: 0.9569 - val_loss: 0.8177 - val_accuracy: 0.7560\n",
      "Epoch 25/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1113 - accuracy: 0.9624\n",
      "Epoch 25: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 150ms/step - loss: 0.1113 - accuracy: 0.9624 - val_loss: 0.8382 - val_accuracy: 0.7505\n",
      "Epoch 26/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0975 - accuracy: 0.9686\n",
      "Epoch 26: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 149ms/step - loss: 0.0975 - accuracy: 0.9686 - val_loss: 0.8818 - val_accuracy: 0.7689\n",
      "Epoch 27/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0889 - accuracy: 0.9717\n",
      "Epoch 27: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 148ms/step - loss: 0.0889 - accuracy: 0.9717 - val_loss: 0.8807 - val_accuracy: 0.7449\n",
      "Epoch 28/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0731 - accuracy: 0.9778\n",
      "Epoch 28: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 148ms/step - loss: 0.0731 - accuracy: 0.9778 - val_loss: 1.2229 - val_accuracy: 0.7486\n",
      "Epoch 29/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9760\n",
      "Epoch 29: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 149ms/step - loss: 0.0794 - accuracy: 0.9760 - val_loss: 0.9805 - val_accuracy: 0.7560\n",
      "Epoch 30/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.9717\n",
      "Epoch 30: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 149ms/step - loss: 0.0783 - accuracy: 0.9717 - val_loss: 1.0216 - val_accuracy: 0.7523\n",
      "Epoch 31/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 0.9754\n",
      "Epoch 31: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 148ms/step - loss: 0.0717 - accuracy: 0.9754 - val_loss: 1.0143 - val_accuracy: 0.7652\n",
      "Epoch 32/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9803\n",
      "Epoch 32: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 148ms/step - loss: 0.0581 - accuracy: 0.9803 - val_loss: 1.0447 - val_accuracy: 0.7542\n",
      "Epoch 33/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9821\n",
      "Epoch 33: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 148ms/step - loss: 0.0509 - accuracy: 0.9821 - val_loss: 1.0279 - val_accuracy: 0.7505\n",
      "Epoch 34/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0532 - accuracy: 0.9827\n",
      "Epoch 34: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 149ms/step - loss: 0.0532 - accuracy: 0.9827 - val_loss: 1.0548 - val_accuracy: 0.7652\n",
      "Epoch 35/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9809\n",
      "Epoch 35: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 149ms/step - loss: 0.0450 - accuracy: 0.9809 - val_loss: 1.1141 - val_accuracy: 0.7523\n",
      "Epoch 36/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.9815\n",
      "Epoch 36: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 153ms/step - loss: 0.0533 - accuracy: 0.9815 - val_loss: 1.0668 - val_accuracy: 0.7523\n",
      "Epoch 37/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9834\n",
      "Epoch 37: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 150ms/step - loss: 0.0421 - accuracy: 0.9834 - val_loss: 1.0669 - val_accuracy: 0.7468\n",
      "Epoch 38/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9846\n",
      "Epoch 38: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 148ms/step - loss: 0.0408 - accuracy: 0.9846 - val_loss: 1.1371 - val_accuracy: 0.7671\n",
      "Epoch 39/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.9852\n",
      "Epoch 39: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 151ms/step - loss: 0.0400 - accuracy: 0.9852 - val_loss: 1.1549 - val_accuracy: 0.7468\n",
      "Epoch 40/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9883\n",
      "Epoch 40: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 159ms/step - loss: 0.0348 - accuracy: 0.9883 - val_loss: 1.2115 - val_accuracy: 0.7579\n",
      "Epoch 41/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9889\n",
      "Epoch 41: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 7s 142ms/step - loss: 0.0343 - accuracy: 0.9889 - val_loss: 1.2005 - val_accuracy: 0.7579\n",
      "Epoch 42/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9926\n",
      "Epoch 42: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 152ms/step - loss: 0.0210 - accuracy: 0.9926 - val_loss: 1.2147 - val_accuracy: 0.7542\n",
      "Epoch 43/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9938\n",
      "Epoch 43: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 150ms/step - loss: 0.0238 - accuracy: 0.9938 - val_loss: 1.2366 - val_accuracy: 0.7652\n",
      "Epoch 44/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9901\n",
      "Epoch 44: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 7s 147ms/step - loss: 0.0301 - accuracy: 0.9901 - val_loss: 1.2779 - val_accuracy: 0.7597\n",
      "Epoch 45/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9938\n",
      "Epoch 45: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 148ms/step - loss: 0.0205 - accuracy: 0.9938 - val_loss: 1.3103 - val_accuracy: 0.7579\n",
      "Epoch 46/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9871\n",
      "Epoch 46: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 155ms/step - loss: 0.0368 - accuracy: 0.9871 - val_loss: 1.3239 - val_accuracy: 0.7505\n",
      "Epoch 47/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9914\n",
      "Epoch 47: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 152ms/step - loss: 0.0311 - accuracy: 0.9914 - val_loss: 1.2684 - val_accuracy: 0.7523\n",
      "Epoch 48/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9938\n",
      "Epoch 48: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 148ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 1.2807 - val_accuracy: 0.7579\n",
      "Epoch 49/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9908\n",
      "Epoch 49: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 150ms/step - loss: 0.0239 - accuracy: 0.9908 - val_loss: 1.2671 - val_accuracy: 0.7449\n",
      "Epoch 50/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9926\n",
      "Epoch 50: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 149ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 1.3397 - val_accuracy: 0.7523\n",
      "Epoch 51/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9938\n",
      "Epoch 51: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 156ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 1.2984 - val_accuracy: 0.7726\n",
      "Epoch 52/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9945\n",
      "Epoch 52: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 154ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 1.3605 - val_accuracy: 0.7431\n",
      "Epoch 53/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9951\n",
      "Epoch 53: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 151ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 1.3631 - val_accuracy: 0.7560\n",
      "Epoch 54/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9957\n",
      "Epoch 54: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 159ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 1.4118 - val_accuracy: 0.7542\n",
      "Epoch 55/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9982\n",
      "Epoch 55: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 152ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 1.5011 - val_accuracy: 0.7505\n",
      "Epoch 56/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9963\n",
      "Epoch 56: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 152ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 1.4609 - val_accuracy: 0.7634\n",
      "Epoch 57/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9957\n",
      "Epoch 57: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 150ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 1.4752 - val_accuracy: 0.7486\n",
      "Epoch 58/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9920\n",
      "Epoch 58: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 152ms/step - loss: 0.0218 - accuracy: 0.9920 - val_loss: 1.4403 - val_accuracy: 0.7616\n",
      "Epoch 59/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9932\n",
      "Epoch 59: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 151ms/step - loss: 0.0171 - accuracy: 0.9932 - val_loss: 1.3726 - val_accuracy: 0.7652\n",
      "Epoch 60/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9994\n",
      "Epoch 60: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 155ms/step - loss: 0.0064 - accuracy: 0.9994 - val_loss: 1.4359 - val_accuracy: 0.7616\n",
      "Epoch 61/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9963\n",
      "Epoch 61: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 157ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 1.5322 - val_accuracy: 0.7616\n",
      "Epoch 62/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9963\n",
      "Epoch 62: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 155ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 1.5272 - val_accuracy: 0.7616\n",
      "Epoch 63/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9963\n",
      "Epoch 63: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 154ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 1.4767 - val_accuracy: 0.7542\n",
      "Epoch 64/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9932\n",
      "Epoch 64: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 159ms/step - loss: 0.0174 - accuracy: 0.9932 - val_loss: 1.4214 - val_accuracy: 0.7542\n",
      "Epoch 65/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9994\n",
      "Epoch 65: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 159ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 1.4711 - val_accuracy: 0.7523\n",
      "Epoch 66/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9982\n",
      "Epoch 66: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 160ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 1.4336 - val_accuracy: 0.7505\n",
      "Epoch 67/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9988\n",
      "Epoch 67: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 9s 184ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 1.5306 - val_accuracy: 0.7486\n",
      "Epoch 68/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9988\n",
      "Epoch 68: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 8s 164ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 1.5308 - val_accuracy: 0.7560\n",
      "Epoch 69/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9969\n",
      "Epoch 69: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 9s 176ms/step - loss: 0.0072 - accuracy: 0.9969 - val_loss: 1.5941 - val_accuracy: 0.7523\n",
      "Epoch 70/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9982\n",
      "Epoch 70: val_accuracy did not improve from 0.78373\n",
      "51/51 [==============================] - 9s 167ms/step - loss: 0.0093 - accuracy: 0.9982 - val_loss: 1.5936 - val_accuracy: 0.7671\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
    "model2.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))\n",
    "model2.add(layers.Dense(3,activation='softmax'))\n",
    "model2.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#Implementing model checkpoins to save the best metric and do not lose it on training.\n",
    "checkpoint2 = ModelCheckpoint(\"best_model2.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
    "history = model2.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c428fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb8cc5fd",
   "metadata": {},
   "source": [
    "## 1D Convolutional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "10d81a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/70\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 1.6777 - acc: 0.5708WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 4s 43ms/step - loss: 1.6666 - acc: 0.5705 - val_loss: 1.3625 - val_acc: 0.5323\n",
      "Epoch 2/70\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 1.1721 - acc: 0.5682WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 1.1648 - acc: 0.5699 - val_loss: 1.0526 - val_acc: 0.5323\n",
      "Epoch 3/70\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.9552 - acc: 0.6465WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.9544 - acc: 0.6470 - val_loss: 0.9220 - val_acc: 0.6932\n",
      "Epoch 4/70\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.8820 - acc: 0.6906WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.8823 - acc: 0.6901 - val_loss: 0.8812 - val_acc: 0.6987\n",
      "Epoch 5/70\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.8510 - acc: 0.7038WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 23ms/step - loss: 0.8522 - acc: 0.7018 - val_loss: 0.8536 - val_acc: 0.7043\n",
      "Epoch 6/70\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.8269 - acc: 0.7075WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.8290 - acc: 0.7055 - val_loss: 0.8430 - val_acc: 0.7006\n",
      "Epoch 7/70\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 0.8057 - acc: 0.7117WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 0.8085 - acc: 0.7086 - val_loss: 0.8255 - val_acc: 0.7209\n",
      "Epoch 8/70\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.7887 - acc: 0.7169WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 23ms/step - loss: 0.7901 - acc: 0.7153 - val_loss: 0.8068 - val_acc: 0.7264\n",
      "Epoch 9/70\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 0.7736 - acc: 0.7277WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.7746 - acc: 0.7252 - val_loss: 0.7994 - val_acc: 0.7246\n",
      "Epoch 10/70\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.7562 - acc: 0.7262WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 0.7544 - acc: 0.7277 - val_loss: 0.7904 - val_acc: 0.7320\n",
      "Epoch 11/70\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.7378 - acc: 0.7387WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 0.7365 - acc: 0.7394 - val_loss: 0.7821 - val_acc: 0.7394\n",
      "Epoch 12/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.7172 - acc: 0.7542WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.7172 - acc: 0.7542 - val_loss: 0.7789 - val_acc: 0.7283\n",
      "Epoch 13/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.6969 - acc: 0.7659WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 0.6969 - acc: 0.7659 - val_loss: 0.7657 - val_acc: 0.7394\n",
      "Epoch 14/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.6762 - acc: 0.7689WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.6762 - acc: 0.7689 - val_loss: 0.7717 - val_acc: 0.7301\n",
      "Epoch 15/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.6537 - acc: 0.7831WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.6537 - acc: 0.7831 - val_loss: 0.7524 - val_acc: 0.7449\n",
      "Epoch 16/70\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.6346 - acc: 0.7900WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.6321 - acc: 0.7911 - val_loss: 0.7542 - val_acc: 0.7412\n",
      "Epoch 17/70\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.6204 - acc: 0.7943WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.6129 - acc: 0.7967 - val_loss: 0.7429 - val_acc: 0.7542\n",
      "Epoch 18/70\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.5880 - acc: 0.8106WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.5900 - acc: 0.8096 - val_loss: 0.7295 - val_acc: 0.7560\n",
      "Epoch 19/70\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.5651 - acc: 0.8158WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 0.5652 - acc: 0.8152 - val_loss: 0.7208 - val_acc: 0.7634\n",
      "Epoch 20/70\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.5462 - acc: 0.8294WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.5480 - acc: 0.8299 - val_loss: 0.7110 - val_acc: 0.7671\n",
      "Epoch 21/70\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.5284 - acc: 0.8379WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.5268 - acc: 0.8380 - val_loss: 0.7055 - val_acc: 0.7726\n",
      "Epoch 22/70\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.5090 - acc: 0.8444WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.5066 - acc: 0.8466 - val_loss: 0.7015 - val_acc: 0.7726\n",
      "Epoch 23/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.4859 - acc: 0.8509WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.4859 - acc: 0.8509 - val_loss: 0.6906 - val_acc: 0.7800\n",
      "Epoch 24/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.4694 - acc: 0.8571WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 0.4694 - acc: 0.8571 - val_loss: 0.6887 - val_acc: 0.7837\n",
      "Epoch 25/70\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.4504 - acc: 0.8672WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.4507 - acc: 0.8644 - val_loss: 0.7003 - val_acc: 0.7819\n",
      "Epoch 26/70\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.4335 - acc: 0.8675WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.4349 - acc: 0.8663 - val_loss: 0.6862 - val_acc: 0.7893\n",
      "Epoch 27/70\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.4185 - acc: 0.8704WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.4184 - acc: 0.8706 - val_loss: 0.6916 - val_acc: 0.7948\n",
      "Epoch 28/70\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 0.4044 - acc: 0.8763WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.4056 - acc: 0.8749 - val_loss: 0.6942 - val_acc: 0.7930\n",
      "Epoch 29/70\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3939 - acc: 0.8756WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.3929 - acc: 0.8755 - val_loss: 0.7059 - val_acc: 0.7948\n",
      "Epoch 30/70\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 0.3824 - acc: 0.8782WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 0.3803 - acc: 0.8786 - val_loss: 0.7051 - val_acc: 0.7967\n",
      "Epoch 31/70\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3695 - acc: 0.8800WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 0.3696 - acc: 0.8799 - val_loss: 0.7096 - val_acc: 0.7967\n",
      "Epoch 32/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3579 - acc: 0.8854WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.3579 - acc: 0.8854 - val_loss: 0.7387 - val_acc: 0.8022\n",
      "Epoch 33/70\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 0.3495 - acc: 0.8980WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.3496 - acc: 0.8965 - val_loss: 0.7282 - val_acc: 0.7967\n",
      "Epoch 34/70\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 0.3407 - acc: 0.9062WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.3391 - acc: 0.9057 - val_loss: 0.7399 - val_acc: 0.7948\n",
      "Epoch 35/70\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.3248 - acc: 0.9212WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.3281 - acc: 0.9217 - val_loss: 0.7514 - val_acc: 0.7948\n",
      "Epoch 36/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3203 - acc: 0.9365WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 0.3203 - acc: 0.9365 - val_loss: 0.7688 - val_acc: 0.7930\n",
      "Epoch 37/70\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3118 - acc: 0.9469WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.3115 - acc: 0.9470 - val_loss: 0.7736 - val_acc: 0.7856\n",
      "Epoch 38/70\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 0.2961 - acc: 0.9528WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.3009 - acc: 0.9532 - val_loss: 0.7930 - val_acc: 0.7819\n",
      "Epoch 39/70\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.2926 - acc: 0.9570WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.2944 - acc: 0.9563 - val_loss: 0.8063 - val_acc: 0.7800\n",
      "Epoch 40/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2858 - acc: 0.9624WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 0.2858 - acc: 0.9624 - val_loss: 0.8235 - val_acc: 0.7782\n",
      "Epoch 41/70\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.2782 - acc: 0.9644WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.2779 - acc: 0.9643 - val_loss: 0.8455 - val_acc: 0.7708\n",
      "Epoch 42/70\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.2718 - acc: 0.9648WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 0.2708 - acc: 0.9643 - val_loss: 0.8616 - val_acc: 0.7745\n",
      "Epoch 43/70\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 0.2652 - acc: 0.9694WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.2640 - acc: 0.9704 - val_loss: 0.8750 - val_acc: 0.7800\n",
      "Epoch 44/70\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 0.2556 - acc: 0.9732WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.2565 - acc: 0.9729 - val_loss: 0.9021 - val_acc: 0.7708\n",
      "Epoch 45/70\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 0.2495 - acc: 0.9739WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.2493 - acc: 0.9735 - val_loss: 0.9152 - val_acc: 0.7800\n",
      "Epoch 46/70\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.2452 - acc: 0.9759WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.2437 - acc: 0.9754 - val_loss: 0.9359 - val_acc: 0.7652\n",
      "Epoch 47/70\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.2380 - acc: 0.9794WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.2379 - acc: 0.9791 - val_loss: 0.9456 - val_acc: 0.7689\n",
      "Epoch 48/70\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.2325 - acc: 0.9762WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.2316 - acc: 0.9766 - val_loss: 0.9676 - val_acc: 0.7689\n",
      "Epoch 49/70\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.2282 - acc: 0.9805WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.2280 - acc: 0.9797 - val_loss: 0.9855 - val_acc: 0.7671\n",
      "Epoch 50/70\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 0.2236 - acc: 0.9828WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.2222 - acc: 0.9834 - val_loss: 0.9990 - val_acc: 0.7597\n",
      "Epoch 51/70\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 0.2180 - acc: 0.9821WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.2174 - acc: 0.9827 - val_loss: 1.0100 - val_acc: 0.7652\n",
      "Epoch 52/70\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.2139 - acc: 0.9824WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.2123 - acc: 0.9834 - val_loss: 1.0158 - val_acc: 0.7689\n",
      "Epoch 53/70\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 0.2086 - acc: 0.9841WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.2085 - acc: 0.9840 - val_loss: 1.0297 - val_acc: 0.7652\n",
      "Epoch 54/70\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.2034 - acc: 0.9844WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.2028 - acc: 0.9846 - val_loss: 1.0450 - val_acc: 0.7708\n",
      "Epoch 55/70\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 0.2014 - acc: 0.9872WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.2005 - acc: 0.9871 - val_loss: 1.0527 - val_acc: 0.7634\n",
      "Epoch 56/70\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 0.1967 - acc: 0.9866WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1949 - acc: 0.9871 - val_loss: 1.0690 - val_acc: 0.7616\n",
      "Epoch 57/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1916 - acc: 0.9877WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1916 - acc: 0.9877 - val_loss: 1.0899 - val_acc: 0.7671\n",
      "Epoch 58/70\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.1863 - acc: 0.9887WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 0.1880 - acc: 0.9883 - val_loss: 1.1129 - val_acc: 0.7597\n",
      "Epoch 59/70\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.1855 - acc: 0.9881WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 0.1860 - acc: 0.9877 - val_loss: 1.1014 - val_acc: 0.7616\n",
      "Epoch 60/70\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.1815 - acc: 0.9896WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.1822 - acc: 0.9895 - val_loss: 1.1190 - val_acc: 0.7634\n",
      "Epoch 61/70\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.1800 - acc: 0.9887WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.1795 - acc: 0.9889 - val_loss: 1.1168 - val_acc: 0.7579\n",
      "Epoch 62/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1751 - acc: 0.9895WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.1751 - acc: 0.9895 - val_loss: 1.1047 - val_acc: 0.7652\n",
      "Epoch 63/70\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.1740 - acc: 0.9883WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.1727 - acc: 0.9889 - val_loss: 1.1348 - val_acc: 0.7597\n",
      "Epoch 64/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1691 - acc: 0.9908WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 0.1691 - acc: 0.9908 - val_loss: 1.1406 - val_acc: 0.7689\n",
      "Epoch 65/70\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.1667 - acc: 0.9889WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.1657 - acc: 0.9889 - val_loss: 1.1456 - val_acc: 0.7634\n",
      "Epoch 66/70\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 0.1631 - acc: 0.9911WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 0.1641 - acc: 0.9908 - val_loss: 1.1713 - val_acc: 0.7597\n",
      "Epoch 67/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1601 - acc: 0.9920WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 0.1601 - acc: 0.9920 - val_loss: 1.1676 - val_acc: 0.7449\n",
      "Epoch 68/70\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1568 - acc: 0.9920WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.1568 - acc: 0.9920 - val_loss: 1.1520 - val_acc: 0.7523\n",
      "Epoch 69/70\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.1517 - acc: 0.9928WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 0.1540 - acc: 0.9920 - val_loss: 1.1703 - val_acc: 0.7652\n",
      "Epoch 70/70\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.1522 - acc: 0.9912WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.1518 - acc: 0.9914 - val_loss: 1.1715 - val_acc: 0.7560\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "model3 = Sequential()\n",
    "model3.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
    "model3.add(layers.Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
    "model3.add(layers.MaxPooling1D(5))\n",
    "model3.add(layers.Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
    "model3.add(layers.GlobalMaxPooling1D())\n",
    "model3.add(layers.Dense(3,activation='softmax'))\n",
    "model3.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['acc'])\n",
    "checkpoint3 = ModelCheckpoint(\"best_model3.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
    "history = model3.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e654e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1df987d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ff3e802",
   "metadata": {},
   "source": [
    "## Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "265ff2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = keras.models.load_model(\"best_model2.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1903cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 - 3s - loss: 0.5798 - accuracy: 0.7837 - 3s/epoch - 183ms/step\n",
      "Model accuracy:  0.7837338447570801\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Model accuracy: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9dc0df73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 2s 39ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc3a0954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test.argmax(axis=1), np.around(predictions, decimals=0).argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ad2d0164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "conf_matrix = pd.DataFrame(matrix, index = ['Neutral','Negative','Positive'],columns = ['Neutral','Negative','Positive'])\n",
    "#Normalizing\n",
    "conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure(figsize = (15,15))\n",
    "sns.heatmap(conf_matrix, annot=True, annot_kws={\"size\": 15})\n",
    "plt.savefig('confmatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2815380e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b4765e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fe881e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0dbdc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33674bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
